# ğŸ¤– Configuration GitHub Actions

Ce guide explique comment configurer l'exÃ©cution automatique du scraper toutes les 30 minutes.

## â° Planning d'exÃ©cution

Le workflow s'exÃ©cute automatiquement **toutes les 30 minutes** avec un **dÃ©calage de 5 minutes** :

- âœ… 00:05, 00:35
- âœ… 01:05, 01:35
- âœ… 02:05, 02:35
- âœ… ... et ainsi de suite

Ce dÃ©calage de 5 minutes permet de **ne pas rater les cotes qui apparaissent pile Ã  l'heure** (20:00:00, 21:00:00, etc.).

## ğŸ“‹ PrÃ©requis

1. CrÃ©er un repository GitHub
2. Activer GitHub Actions (gratuit pour les repos publics)

## ğŸš€ Installation

### 1. CrÃ©er le repository

```bash
# Depuis votre smartphone, utilisez l'app GitHub ou via le navigateur
# CrÃ©er un nouveau repository : winamax-scraper
```

### 2. Pousser le code

```bash
git init
git add .
git commit -m "Initial commit: Winamax scraper"
git branch -M main
git remote add origin https://github.com/VOTRE_USERNAME/winamax-scraper.git
git push -u origin main
```

### 3. Activer GitHub Actions

Le workflow dans `.github/workflows/scrape_cotes.yml` sera automatiquement dÃ©tectÃ© et activÃ©.

## ğŸ”§ Configuration du workflow

### Horaires personnalisÃ©s

Pour modifier les horaires, Ã©ditez `.github/workflows/scrape_cotes.yml` :

```yaml
on:
  schedule:
    # Format cron: minute heure jour mois jour_semaine
    - cron: '5,35 * * * *'  # Actuel: :05 et :35 de chaque heure
    
    # Exemples d'autres configurations:
    # - cron: '0,30 * * * *'  # :00 et :30 (Ã  l'heure pile)
    # - cron: '10,40 * * * *' # :10 et :40
    # - cron: '*/15 * * * *'  # Toutes les 15 minutes
    # - cron: '0 * * * *'     # Toutes les heures Ã  :00
```

### ExÃ©cution manuelle

Depuis GitHub.com :
1. Aller dans l'onglet **Actions**
2. SÃ©lectionner le workflow "Scrape Cotes BoostÃ©es Winamax"
3. Cliquer sur **Run workflow**

### MÃ©thode de scraping

Par dÃ©faut, le workflow utilise **Playwright** (rapide et fiable).

Pour changer la mÃ©thode, Ã©ditez le fichier workflow :

```yaml
- name: ğŸ¯ Run scraper
  run: |
    python main.py --method playwright --export all  # MÃ©thode actuelle
    # python main.py --method selenium --export all   # Alternative
    # python main.py --method ocr --export all        # OCR
    # python main.py --method all --export all        # Toutes les mÃ©thodes
```

## ğŸ“Š Consulter les rÃ©sultats

### Via GitHub

1. Les rÃ©sultats sont automatiquement **commit et push** dans le dossier `output/`
2. Naviguez dans votre repo : `output/json/` ou `output/csv/`

### Structure des fichiers

```
output/
â”œâ”€â”€ json/
â”‚   â”œâ”€â”€ cotes_2026-01-03_14-05-30.json
â”‚   â”œâ”€â”€ cotes_2026-01-03_14-35-15.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ csv/
â”‚   â”œâ”€â”€ cotes_2026-01-03_14-05-30.csv
â”‚   â””â”€â”€ ...
â””â”€â”€ screenshots/
    â”œâ”€â”€ playwright_2026-01-03_14-05-30.png
    â””â”€â”€ ...
```

### Depuis votre smartphone

- **App GitHub** : Naviguez dans les fichiers du repo
- **GitHub Mobile** : Voir les commits et les fichiers
- **Navigateur web** : github.com/VOTRE_USERNAME/winamax-scraper

## ğŸ” VÃ©rifier l'exÃ©cution

### Logs en temps rÃ©el

1. Onglet **Actions**
2. Cliquer sur une exÃ©cution
3. Voir les logs dÃ©taillÃ©s de chaque Ã©tape

### Notifications

GitHub envoie des emails en cas d'Ã©chec du workflow.

Pour personnaliser les notifications :
- **Settings** â†’ **Notifications** â†’ **Actions**

## âš ï¸ Limites GitHub Actions

### Plan gratuit (repos publics)
- âœ… Minutes illimitÃ©es
- âœ… Stockage : 500 MB
- âœ… Pas de limite d'exÃ©cutions

### Plan gratuit (repos privÃ©s)
- âš ï¸ 2000 minutes/mois
- âš ï¸ Stockage : 500 MB

### Calcul de consommation

Avec 30 minutes d'intervalle :
- 48 exÃ©cutions/jour
- ~2 minutes/exÃ©cution
- **~96 minutes/jour** pour un repo privÃ©

ğŸ’¡ **Solution** : Utilisez un repository **public** pour des exÃ©cutions illimitÃ©es.

## ğŸ›‘ ArrÃªter le scraping automatique

### Temporairement

1. Onglet **Actions**
2. Workflow "Scrape Cotes BoostÃ©es"
3. â‹® (menu) â†’ **Disable workflow**

### DÃ©finitivement

Supprimer ou commenter dans `.github/workflows/scrape_cotes.yml` :

```yaml
on:
  # schedule:
  #   - cron: '5,35 * * * *'
  workflow_dispatch:  # Garder l'exÃ©cution manuelle
```

## ğŸ” SÃ©curitÃ©

### Tokens et secrets

Le workflow utilise automatiquement `GITHUB_TOKEN` pour :
- Commit les rÃ©sultats
- Push vers le repository

Aucune configuration supplÃ©mentaire n'est nÃ©cessaire.

### DonnÃ©es sensibles

âš ï¸ Les donnÃ©es scrapÃ©es sont **publiques** si votre repo est public.

Pour un repo privÃ© :
1. **Settings** â†’ **General**
2. Scroll vers le bas
3. **Change repository visibility** â†’ Private

## ğŸ“± Utilisation depuis smartphone

### Voir les rÃ©sultats

1. **GitHub Mobile App** : TÃ©lÃ©chargez l'app officielle
2. Naviguez vers votre repo
3. Consultez les fichiers dans `output/`

### TÃ©lÃ©charger les donnÃ©es

- Depuis l'app : View raw â†’ Share â†’ TÃ©lÃ©charger
- Depuis le web : Cliquer sur le fichier â†’ Download

### ExÃ©cuter manuellement

1. App GitHub â†’ Repo â†’ Actions
2. Workflow â†’ Run workflow â†’ Run

## ğŸ› DÃ©pannage

### Le workflow ne s'exÃ©cute pas

```bash
# VÃ©rifier que le fichier workflow est au bon endroit
.github/workflows/scrape_cotes.yml

# VÃ©rifier la syntaxe YAML
# Utilisez un validateur YAML en ligne
```

### Erreurs de permissions

Si le push Ã©choue :

1. **Settings** â†’ **Actions** â†’ **General**
2. **Workflow permissions**
3. SÃ©lectionner **Read and write permissions**
4. Sauvegarder

### Aucune donnÃ©e extraite

- VÃ©rifier les logs du workflow
- Le site a peut-Ãªtre changÃ© de structure
- Essayer une autre mÃ©thode de scraping

## ğŸ’¡ Astuces

### Combiner avec d'autres outils

Export automatique vers :
- **Google Sheets** : Utiliser une GitHub Action tierce
- **Discord/Telegram** : Notifications avec webhooks
- **Email** : Alertes via SendGrid

### Optimisation

```yaml
# Utiliser le cache pour accÃ©lÃ©rer
- name: Cache pip dependencies
  uses: actions/cache@v3
  with:
    path: ~/.cache/pip
    key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
```

## ğŸ“ˆ Monitoring

### Tableau de bord

CrÃ©ez un fichier `dashboard.md` avec un script qui analyse les JSON :

```python
# GÃ©nÃ©rer des statistiques
# - Nombre de cotes par jour
# - Cotes les plus frÃ©quentes
# - Meilleurs boosts
```

### Alertes personnalisÃ©es

Ajoutez une Ã©tape dans le workflow pour envoyer des alertes si certaines conditions sont remplies :

```yaml
- name: ğŸ”” Check for high odds
  run: |
    python check_odds.py --threshold 5.0
```

## âœ… Checklist de dÃ©ploiement

- [ ] Repository crÃ©Ã© sur GitHub
- [ ] Code pushÃ© avec tous les fichiers
- [ ] Workflow prÃ©sent dans `.github/workflows/`
- [ ] Permissions "Read and write" activÃ©es
- [ ] Premier test d'exÃ©cution manuelle rÃ©ussi
- [ ] VÃ©rification que les rÃ©sultats sont commit
- [ ] Application mobile installÃ©e (optionnel)

## ğŸ‰ C'est prÃªt !

Votre scraper tournera automatiquement toutes les 30 minutes et vous ne raterez plus aucune cote boostÃ©e ! ğŸš€
